{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f82c9-5bb1-4cbf-97c5-084976b14b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/how_to/streaming/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32fa58de-e161-4afb-b871-5d7df8b6a69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.4\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2da6a07d-0d4a-43fa-9585-db25cdecaafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "728f6583-ffce-452a-8023-ba78ecce262f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 0.2.9\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain-openai | grep \"Version:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be6a9afe-e358-4ed8-a066-1c9853df011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f51bd7d5-9165-45fd-a700-85f67592b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c436802f-9fc7-42ea-b50c-4d50c6e653ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf675e3-a9cd-4113-b493-037954ba58df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /home/rajaraman/miniconda3/envs/ml312/lib/python3.12/site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /home/rajaraman/miniconda3/envs/ml312/lib/python3.12/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/rajaraman/miniconda3/envs/ml312/lib/python3.12/site-packages (from faiss-cpu) (24.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7352f984-34c2-4dac-934c-270a85a952de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(metadata={}, page_content='harrison worked at kensho'),\n",
       "  Document(metadata={}, page_content='harrison likes spicy food')]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"harrison worked at kensho\", \"harrison likes spicy food\"],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "chunks = [chunk for chunk in retriever.stream(\"where did harrison work?\")]\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc2c2931-c3f1-4dcf-bd2a-6988a2b8f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = (\n",
    "    {\n",
    "        \"context\": retriever.with_config(run_name=\"Docs\"),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88448ceb-c2ee-4885-8b53-a4d4d7de4629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|H|arrison| worked| at| Kens|ho|.| Kens|ho| is| a| vibrant| company| known| for| its| innovative| approach| to| data| analytics|.| The| office| is| adorned| with| modern| decor| and| features| an| open| layout| that| fosters| collaboration| among| team| members|.| Employees| at| Kens|ho| enjoy| regular| team|-building| activities| that| promote| a| strong| sense| of| community| and| creativity|.||"
     ]
    }
   ],
   "source": [
    "for chunk in retrieval_chain.stream(\n",
    "    \"Where did harrison work? \" \"Write 3 made up sentences about this place.\"\n",
    "):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98bc5507-7628-4afc-9f63-6e5c8b4b3f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harrison worked at Kensho. Kensho is a vibrant tech company known for its innovative approach to data analytics. The office is filled with creative spaces that encourage collaboration among team members. Employees often gather in the cafÃ© to enjoy gourmet coffee and discuss the latest trends in technology."
     ]
    }
   ],
   "source": [
    "for chunk in retrieval_chain.stream(\n",
    "    \"Where did harrison work? \" \"Write 3 made up sentences about this place.\"\n",
    "):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4d5ba5-da0f-45cd-9dc6-60bd9286c3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "111b4a73-983e-45bd-b10b-a74761c41f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = []\n",
    "async for event in model.astream_events(\"hello\", version=\"v2\"):\n",
    "    events.append(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33a7ffce-c8d6-4fb4-91b3-c6233aa0f4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': 'on_chat_model_start',\n",
       "  'data': {'input': 'hello'},\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'run_id': '32c229ee-ec08-4ccb-9ca3-036689f06873',\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '32c229ee-ec08-4ccb-9ca3-036689f06873',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-32c229ee-ec08-4ccb-9ca3-036689f06873')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '32c229ee-ec08-4ccb-9ca3-036689f06873',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'data': {'chunk': AIMessageChunk(content='Hello', additional_kwargs={}, response_metadata={}, id='run-32c229ee-ec08-4ccb-9ca3-036689f06873')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '32c229ee-ec08-4ccb-9ca3-036689f06873',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'data': {'chunk': AIMessageChunk(content='!', additional_kwargs={}, response_metadata={}, id='run-32c229ee-ec08-4ccb-9ca3-036689f06873')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '32c229ee-ec08-4ccb-9ca3-036689f06873',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'data': {'chunk': AIMessageChunk(content=' How', additional_kwargs={}, response_metadata={}, id='run-32c229ee-ec08-4ccb-9ca3-036689f06873')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '32c229ee-ec08-4ccb-9ca3-036689f06873',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'data': {'chunk': AIMessageChunk(content=' can', additional_kwargs={}, response_metadata={}, id='run-32c229ee-ec08-4ccb-9ca3-036689f06873')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '32c229ee-ec08-4ccb-9ca3-036689f06873',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'data': {'chunk': AIMessageChunk(content=' I', additional_kwargs={}, response_metadata={}, id='run-32c229ee-ec08-4ccb-9ca3-036689f06873')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '32c229ee-ec08-4ccb-9ca3-036689f06873',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'data': {'chunk': AIMessageChunk(content=' assist', additional_kwargs={}, response_metadata={}, id='run-32c229ee-ec08-4ccb-9ca3-036689f06873')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '32c229ee-ec08-4ccb-9ca3-036689f06873',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'data': {'chunk': AIMessageChunk(content=' you', additional_kwargs={}, response_metadata={}, id='run-32c229ee-ec08-4ccb-9ca3-036689f06873')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '32c229ee-ec08-4ccb-9ca3-036689f06873',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'data': {'chunk': AIMessageChunk(content=' today', additional_kwargs={}, response_metadata={}, id='run-32c229ee-ec08-4ccb-9ca3-036689f06873')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '32c229ee-ec08-4ccb-9ca3-036689f06873',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'data': {'chunk': AIMessageChunk(content='?', additional_kwargs={}, response_metadata={}, id='run-32c229ee-ec08-4ccb-9ca3-036689f06873')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '32c229ee-ec08-4ccb-9ca3-036689f06873',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0'}, id='run-32c229ee-ec08-4ccb-9ca3-036689f06873')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_end',\n",
       "  'data': {'output': AIMessageChunk(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0'}, id='run-32c229ee-ec08-4ccb-9ca3-036689f06873')},\n",
       "  'run_id': '32c229ee-ec08-4ccb-9ca3-036689f06873',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.7},\n",
       "  'parent_ids': []}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df855f34-1fd5-45af-9546-f18bf2120393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a86f12c-6ca9-4485-9176-d93085c269e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8006d1e-bf85-4652-b7f2-d5b5f2734cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90a3e191-8cfa-41f2-acab-04e642c7559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    model | JsonOutputParser()\n",
    ")  # Due to a bug in older versions of Langchain, JsonOutputParser did not stream results from some models\n",
    "\n",
    "events = [\n",
    "    event\n",
    "    async for event in chain.astream_events(\n",
    "        \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "        'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "        \"Each country should have the key `name` and `population`\",\n",
    "        version=\"v2\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b162cfb-db2e-406f-b1ea-475d49179831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat model chunk: ''\n",
      "Chat model chunk: 'Here'\n",
      "Chat model chunk: ' is'\n",
      "Chat model chunk: ' the'\n",
      "Chat model chunk: ' requested'\n",
      "Chat model chunk: ' information'\n",
      "Chat model chunk: ' in'\n",
      "Chat model chunk: ' JSON'\n",
      "Chat model chunk: ' format'\n",
      "Chat model chunk: ':\\n\\n'\n",
      "Chat model chunk: '```'\n",
      "Chat model chunk: 'json'\n",
      "Chat model chunk: '\\n'\n",
      "Chat model chunk: '{\\n'\n",
      "Parser chunk: {}\n",
      "Chat model chunk: ' '\n",
      "Chat model chunk: ' \"'\n",
      "Chat model chunk: 'countries'\n",
      "Chat model chunk: '\":'\n",
      "Chat model chunk: ' [\\n'\n",
      "Parser chunk: {'countries': []}\n",
      "Chat model chunk: '   '\n",
      "Chat model chunk: ' {\\n'\n",
      "Parser chunk: {'countries': [{}]}\n",
      "Chat model chunk: '     '\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "num_events = 0\n",
    "\n",
    "async for event in chain.astream_events(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\",\n",
    "    version=\"v2\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        print(\n",
    "            f\"Chat model chunk: {repr(event['data']['chunk'].content)}\",\n",
    "            flush=True,\n",
    "        )\n",
    "    if kind == \"on_parser_stream\":\n",
    "        print(f\"Parser chunk: {event['data']['chunk']}\", flush=True)\n",
    "    num_events += 1\n",
    "    if num_events > 30:\n",
    "        # Truncate the output\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e58d28-ab88-41a7-a74a-cdee2f6f1837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f640a069-1a1a-4a85-be11-77e065778b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
