{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd7659a3-7179-4301-a37c-71f199a5ce01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.4\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2da6a07d-0d4a-43fa-9585-db25cdecaafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "728f6583-ffce-452a-8023-ba78ecce262f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 0.2.9\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain-openai | grep \"Version:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be6a9afe-e358-4ed8-a066-1c9853df011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f51bd7d5-9165-45fd-a700-85f67592b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c436802f-9fc7-42ea-b50c-4d50c6e653ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6c3be-f0fa-4857-862a-43627bc25c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68f1ae91-e8fa-4ea7-8530-49b447d9189f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='12', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 14, 'total_tokens': 15, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3af15294-79ee-49da-9117-d7fddf6aa313-0', usage_metadata={'input_tokens': 14, 'output_tokens': 1, 'total_tokens': 15, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def length_function(text):\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "def _multiple_length_function(text1, text2):\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "\n",
    "def multiple_length_function(_dict):\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"what is {a} + {b}\")\n",
    "\n",
    "chain1 = prompt | model\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"a\": itemgetter(\"foo\") | RunnableLambda(length_function),\n",
    "        \"b\": {\"text1\": itemgetter(\"foo\"), \"text2\": itemgetter(\"bar\")}\n",
    "        | RunnableLambda(multiple_length_function),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c99ed54-3890-4c6b-8e09-cdccd3a9986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"foo\": \"ball\", \"bar\": \"gah\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33faf948-f3e2-41c2-adf9-f54cdfee19e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea89a1ea-c80d-4317-9628-7b7618cc19cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "additional_kwargs": {
        "refusal": null
       },
       "content": "4 + 12 equals 16.",
       "example": false,
       "id": "run-f50ddf81-edc2-4048-9cdb-3d7a679171dd-0",
       "invalid_tool_calls": [],
       "name": null,
       "response_metadata": {
        "finish_reason": "stop",
        "logprobs": null,
        "model_name": "gpt-3.5-turbo-0125",
        "system_fingerprint": null,
        "token_usage": {
         "completion_tokens": 8,
         "completion_tokens_details": {
          "accepted_prediction_tokens": 0,
          "audio_tokens": 0,
          "reasoning_tokens": 0,
          "rejected_prediction_tokens": 0
         },
         "prompt_tokens": 14,
         "prompt_tokens_details": {
          "audio_tokens": 0,
          "cached_tokens": 0
         },
         "total_tokens": 22
        }
       },
       "tool_calls": [],
       "type": "ai",
       "usage_metadata": {
        "input_token_details": {
         "audio": 0,
         "cache_read": 0
        },
        "input_tokens": 14,
        "output_token_details": {
         "audio": 0,
         "reasoning": 0
        },
        "output_tokens": 8,
        "total_tokens": 22
       }
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON(result.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed8533c-1cde-4a22-b867-81d90c022349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
