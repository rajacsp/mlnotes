{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78123cce-61e7-448b-8d49-586a6741e63e",
   "metadata": {},
   "source": [
    "8\n",
    "<br>How to: add message history (memory) to a chain\n",
    "<br>https://python.langchain.com/docs/how_to/message_history/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd7659a3-7179-4301-a37c-71f199a5ce01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.4\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2da6a07d-0d4a-43fa-9585-db25cdecaafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "728f6583-ffce-452a-8023-ba78ecce262f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 0.2.9\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain-openai | grep \"Version:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be6a9afe-e358-4ed8-a066-1c9853df011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f51bd7d5-9165-45fd-a700-85f67592b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c436802f-9fc7-42ea-b50c-4d50c6e653ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7934b528-6b5a-41c8-842b-a32b683590a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50de8a27-c61c-4584-ba46-c2dab9590e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be682c9d-bb87-4221-8e3c-9f94bbc0a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.runnables.hub import HubRunnable\n",
    "\n",
    "prompt = HubRunnable(\"rlm/rag-prompt\").configurable_fields(\n",
    "    owner_repo_commit=ConfigurableField(\n",
    "        id=\"hub_commit\",\n",
    "        name=\"Hub Commit\",\n",
    "        description=\"The Hub commit to pull from\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2be5974-7ba8-4256-ac56-4953656d9a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: foo \\nContext: bar \\nAnswer:\", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"question\": \"foo\", \"context\": \"bar\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fcf3e0-6ac9-4c6f-8db6-d3e9af0d81c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
