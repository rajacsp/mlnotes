{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db25c914-1252-4bae-8dbe-3a20e361bd73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c10588e-e9e7-4b8c-b92b-91104a273df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conda env: ml311; pyv: 3.11.10 (main, Oct  3 2024, 07:29:13) [GCC 11.2.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyutil as pyu\n",
    "pyu.get_local_pyinfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ccb592-b983-4856-a241-5898cab06699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haystack-ai==2.8.0\n",
      "ollama-haystack is not installed in the current environment.\n",
      "python-dotenv==0.21.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pyu.ps2(\"haystack-ai ollama-haystack python-dotenv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e290a4be-0793-4902-b10b-44429cb937f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6054244-33a5-4281-87ea-96886c564a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10bde08-ba50-4c18-a603-f5abf2790765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a82efd-4654-46a8-aa3e-4e06505e9274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec6495a5-696a-4873-9a7f-58eec2d0bde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from translate import Translator\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from deep_translator import GoogleTranslator\n",
    "import argostranslate.package\n",
    "import argostranslate.translate\n",
    "\n",
    "# Step 1: Define an abstract base class (interface)\n",
    "class CustomTranslator(ABC):\n",
    "    @abstractmethod\n",
    "    def translate(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7892ac67-aa3e-463e-a757-4b6593c88bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create concrete implementations of the Shape interface\n",
    "class CTranslatorVanilla(CustomTranslator):\n",
    "\n",
    "    def __init__(self, language_code):\n",
    "        print(\"vanilla init called\")\n",
    "        self.translator = Translator(to_lang=language_code)\n",
    "        \n",
    "    def translate(self, text):\n",
    "        return self.translator.translate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "080c29c1-e61d-454a-8aba-1d65bd5a3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTranslatorLLM(CustomTranslator):\n",
    "\n",
    "    def __init__(self, language_code):\n",
    "        print(\"llm init called\")\n",
    "        model_name = f\"Helsinki-NLP/opus-mt-en-{language_code}\"\n",
    "        self.translator = Translator(to_lang=language_code)\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "        \n",
    "    def translate(self, text):\n",
    "\n",
    "        # Tokenize the input\n",
    "        inputs = self.tokenizer.encode(text, return_tensors=\"pt\", truncation=True)\n",
    "        \n",
    "        # Generate translation\n",
    "        outputs = self.model.generate(inputs, max_length=40, num_beams=4, early_stopping=True)\n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce954d35-2ad2-4e5c-b430-c5e0b8abed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTranslatorDeepT(CustomTranslator):\n",
    "\n",
    "    _instance = None\n",
    "\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        if not cls._instance:\n",
    "            cls._instance = super().__new__(cls)\n",
    "        return cls._instance\n",
    "\n",
    "    def __init__(self, language_code):\n",
    "\n",
    "        if not hasattr(self, \"initialized\"):  # To prevent reinitialization\n",
    "            print(\"DeepT init called\")\n",
    "            self.initialized = True\n",
    "            self.translator = GoogleTranslator(source = 'auto', target = language_code)\n",
    "\n",
    "    def translate(self, text):\n",
    "        return self.translator.translate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8285096-4923-4ba5-99e5-8d18f9a4aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_language_code = \"fi\"\n",
    "\n",
    "# Step 3: Create a Factory class to generate objects\n",
    "class CustomTranslatorFactory:\n",
    "    @staticmethod\n",
    "    def get_custom_translator(translator_type, language_code):\n",
    "        if translator_type == \"vanilla\":\n",
    "            return CTranslatorVanilla(language_code)\n",
    "        elif translator_type == \"llm\":\n",
    "            return CTranslatorLLM(language_code)\n",
    "        elif translator_type == \"deept\":\n",
    "            ctranslator = CTranslatorDeepT(language_code)\n",
    "        elif translator_type == \"argo\":\n",
    "            ctranslator = CTranslatorArgo(language_code)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown translator type: {translator_type}\")\n",
    "\n",
    "        return ctranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4494ad22-9456-4705-b641-cb767bc8371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTranslatorArgo(CustomTranslator):\n",
    "\n",
    "    _instance = None\n",
    "\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        if not cls._instance:\n",
    "            cls._instance = super().__new__(cls)\n",
    "        return cls._instance\n",
    "\n",
    "    def __init__(self, language_code):\n",
    "\n",
    "        if not hasattr(self, \"initialized\"):  # To prevent reinitialization\n",
    "            print(\"Argo init called\")\n",
    "            self.initialized = True\n",
    "            self.language_code = language_code\n",
    "\n",
    "            argostranslate.package.update_package_index()\n",
    "            available_packages = argostranslate.package.get_available_packages()\n",
    "\n",
    "            package_to_install = next(\n",
    "                filter(\n",
    "                    lambda x: x.from_code == \"en\" and x.to_code == language_code,\n",
    "                    available_packages\n",
    "                )\n",
    "            )\n",
    "            argostranslate.package.install_from_path(package_to_install.download())\n",
    "\n",
    "    def translate(self, text):\n",
    "        return argostranslate.translate.translate(text, \"en\", self.language_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "714cbb3f-ffab-4e18-9833-14880b77e310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepT init called\n",
      "kuinka voit?\n",
      "llm init called\n",
      "Mitä kuuluu?\n",
      "Argo init called\n",
      "Missä olet?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajaraman/miniconda3/envs/ml311/lib/python3.11/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/rajaraman/miniconda3/envs/ml311/lib/python3.11/site-packages/stanza/models/tokenize/trainer.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n"
     ]
    }
   ],
   "source": [
    "# Client Code\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Use the factory to create shapes\n",
    "    ctranslator_factory = CustomTranslatorFactory()\n",
    "\n",
    "    current_language_code = \"fi\"\n",
    "    \n",
    "    shape1 = ctranslator_factory.get_custom_translator(\"deept\", current_language_code)\n",
    "    print(shape1.translate(\"how are you?\"))\n",
    "\n",
    "    shape2 = ctranslator_factory.get_custom_translator(\"llm\", current_language_code)\n",
    "    print(shape2.translate(\"how are you?\"))\n",
    "\n",
    "    shape2 = ctranslator_factory.get_custom_translator(\"argo\", current_language_code)\n",
    "    print(shape2.translate(\"where are you?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ebe69e-1676-49a8-93af-6f40f36c2b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0989d2bd-0e51-411c-87e9-ef78488de5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f011e8-5029-4934-a446-17f09ed7d1a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
